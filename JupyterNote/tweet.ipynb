{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ================ TWITTER ======================\n",
    "\n",
    "def get_user_tweets(api, username, count=200):\n",
    "    tweets = api.user_timeline(username, count=count)\n",
    "    texts = [tweet.text for tweet in tweets]\n",
    "    return texts#twitter authentication\n",
    "\n",
    "def get_tweets():\n",
    "    #twitter authentication\n",
    "    CONSUMER_KEY        =  os.getenv('api-key')\n",
    "    CONSUMER_SECRET     =  os.getenv('api-secret-key')\n",
    "    ACCESS_TOKEN        =  os.getenv('access-token')\n",
    "    ACCESS_TOKEN_SECRET =  os.getenv('access-secret-token')\n",
    "    AUTH = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    AUTH.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    api = tweepy.API(AUTH)    \n",
    "    return(get_user_tweets(api, username),api.get_user(username).name)\n",
    "\n",
    "username=\"LaRagazzaTurca_\"\n",
    "all_tweets = get_tweets()[0]\n",
    "name = get_tweets()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mention: 69\n",
      "Total Retweet: 69\n",
      "Total Tweet: 60\n"
     ]
    }
   ],
   "source": [
    "mn=0\n",
    "rt=0\n",
    "tw=0\n",
    "\n",
    "mentions=[]\n",
    "retweets=[]\n",
    "tweets=[]\n",
    "\n",
    "for m in all_tweets:\n",
    "    if m[0] == \"@\":\n",
    "        mn = mn + 1\n",
    "        mentions.append(m)\n",
    "    elif m[0:2] == \"RT\":\n",
    "        rt = rt + 1\n",
    "        retweets.append(m)\n",
    "    else:\n",
    "        tw = tw + 1\n",
    "        tweets.append(m)\n",
    "        \n",
    "print(\"Total Mention:\",mn)\n",
    "print(\"Total Retweet:\",rt)\n",
    "print(\"Total Tweet:\",tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Retweets  \\\n",
      "0  RT @sibirbil: Arkadaşlar ilginiz için çok teşe...   \n",
      "1  RT @munferit1aslan: Bir öğretmenler gününde üz...   \n",
      "2  RT @bbcturkce: #RabiaNazaNeOldu: 3 Senaryo \\n\\...   \n",
      "3  RT @metcihan: Mürsel Küçükal'ın sürünme hareke...   \n",
      "4  RT @BarisAkademik: Barış akademisyenlerinin gö...   \n",
      "\n",
      "                                              Tweets  \\\n",
      "0  #24KasimOgretmenlerGunuKutluOlsun https://t.co...   \n",
      "1  Gölcük'ten Berlin Teknik'e uzanan bir başarı h...   \n",
      "2  \"Bizim zamanımızda da böyleydi\" lafı meğer çoo...   \n",
      "3  Bugün #FountainPenDay. Akşamımı harika kalem, ...   \n",
      "4  #AdanaLezzetFestivali 4, 5, 6 Ekim'de Adana Me...   \n",
      "\n",
      "                                            Mentions  \n",
      "0  @bilimhatunu Düzeltmek kaba değil kesinlikle. ...  \n",
      "1  @pyolum Once ben de @pyolum gibi bir danışman ...  \n",
      "2                              @sibirbil kesinlikle!  \n",
      "3  @Bogazici_CmpE Web sitesinden önce öğrencimizi...  \n",
      "4  @Bogazici_CmpE .@Bogazici_CmpE aile fotoğrafım...  \n"
     ]
    }
   ],
   "source": [
    "df_retweets = pd.DataFrame({'retweets': retweets})\n",
    "df_tweets = pd.DataFrame({'tweets': tweets})\n",
    "df_mentions = pd.DataFrame({'mentions': mentions})\n",
    "\n",
    "df_all=pd.concat([df_retweets,df_tweets,df_mentions],ignore_index=True, axis=1)\n",
    "df_all.columns = [ 'Retweets','Tweets', 'Mentions']\n",
    "\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#24kasimogretmenlergunukutluolsun https://t.co/iszalqdcwg\n",
      "gölcük'ten berlin teknik'e uzanan bir başarı hikayesi #begümdemir i̇yi ki yolumuz trento'da kesişmiş &lt;3 \n",
      "https://t.co/tdjrhxdcrk\n",
      "\"bizim zamanımızda da böyleydi\" lafı meğer çook geriye gidiyormuş. rt @cwjones89: academics complaining that depart… https://t.co/re1yedsptt\n",
      "bugün #fountainpenday. akşamımı harika kalem, mürekkep ve yazı fotoğraflarına bakarak geçiriyorum😍 evdeki bebekleri… https://t.co/7uwbvliqt8\n",
      "#adanalezzetfestivali 4, 5, 6 ekim'de adana merkez park'taymış. festival programında festival mangalının yakılması… https://t.co/ep0dz4d9as\n",
      "avrupa ikinciliği için tebrikler #fileninsultanları\n",
      "finaldeyiz 🇹🇷🇹🇷🇹🇷💃🏻💃🏻💃🏻  #simgeaköz #edaerdem 💜 #fileninsultanları\n",
      "#fileninsultanları hollanda'yı 3-0 skorla devirdi 💪🇹🇷🇹🇷🇹🇷 yarı final cumartesi polonya veya almanya ile\n",
      "#suleceti̇cinadalet rt @suleicinadalet: #suleceti̇cinadalet https://t.co/ghlyl6ykvy\n",
      "#unutmadimaklımda https://t.co/tpllo6knzc\n",
      "bugün her şey çok güzel oldu, ilerde de #herşeyçokgüzelolacak 🇹🇷🇹🇷🇹🇷\n",
      ".@bogazici_cmpe bugün bitirme projesi sunumları ile cıvıl cıvıl! https://t.co/rit4ezwp41\n",
      ".@inzvaspace #ai project showcase etkinliginde pek cok lisansüstü ve lisans @bogazici_cmpe ogrencisi de sahte akade… https://t.co/cfmrmrinux\n",
      ".@buenso organizasyonu #icames19 icin levent akın hocamla jüri üyeliği hatıramız :) farklı ülkelerden mühendislik ö… https://t.co/ktighmuvwj\n",
      "doktora tezini başarıyla sunan @bariskurt danışmanı taylan cemgil ile @bogazici_cmpe https://t.co/a6mbshvgdz\n",
      ". @bariskurt doktora tezini sunmak üzere! https://t.co/zfjshcenb1\n",
      ".@bogazici_cmpe'den @_emre_ugur_ #esnekuretim için #robotik anlatıyor. @buindustry4zero https://t.co/2pjvbwkrje\n",
      "#kitapchallenge'a kaldığım yerden devam edeyim, 6. gün #catch22 #josephheller https://t.co/yo7ayefmcz\n",
      "bu da başka tür #kitapchallenge. yurt dışında büyümüş, türkçeleri çok akıcı olmayan 12 -13 yaşında çocuklar için tü… https://t.co/gya1w4aalr\n",
      "#kitapchallenge 5. gün #jacklondon'dan #martineden \n",
      "\n",
      "@skocacan 7 gün sevdiğin kitapların kapaklarını paylaşır mısın? https://t.co/q8vybpdmnh\n",
      "#kitapchallenge 4. gün, @svlchsn i davet ediyorum :) kitap chimamanda ngozi adichie'den #americanah https://t.co/4cdtkq6i4i\n",
      "#kitapchallenge 3. gün: günün kitabı tanpınar'dan huzur. katılmak isterse @metdos u davet ediyorum. https://t.co/wx1cc2cpvh\n",
      ".@say_cem hocamın daveti de geldi. #kitapchallenge 2. gün. @gundogdudidem sen de gelsene https://t.co/1gqiepbxtv\n",
      "#kitapchallenge 1. gün, @nkokciyan davet etti. @zkiziltoprak var mısın? https://t.co/eqe1lbazrh\n",
      "i̇lk baskıya yetişemedim, 2. baskıdan bir kendime bir de anne babamın köyündeki ilkokula hediyelik kaptım. @say_cem… https://t.co/pmbvylxzfi\n",
      "japon imparatorunun balık bilimi uzmanı olup yayın çıkardığını yeni öğrendim. soyadı yok, adres imparatorluk sarayı… https://t.co/cvok33izyy\n",
      "noordwijk'teki avrupa uzay ajansi'nda mutlu bir ben :) bazı verileri herkese acik, bir kısım veriler ajansa üye olm… https://t.co/dj2ouuhz4z\n",
      "bir arkadasim mobil/web uygulamalar alaninda staj yapabilecegi bir sirket ariyor. ilgilenen biri cikar mi acaba?\n",
      "yazılım mühendisliği ile ilgilenen herkes bugünkü icse davetli konuşmacıların dinlemeli. rt @aydemirfb: highly reco… https://t.co/uvj3hb4lju\n",
      "bilgi universitesi'nden ayhan kaya islam-ophob-ism projesiyle turkiye'den tek isim. tebrikler! https://t.co/n13dol5pyz\n",
      "#remotesensing ve #earthobservation uzerinde calisiyorsaniz harika bir firsat https://t.co/x5mpsa5k7k\n",
      "#hollanda'da yasamanin bir de bu yuzu var: https://t.co/5shyyvmepe\n",
      "neyse bugun bisikleti almamistim https://t.co/cn2persnar\n",
      "turkiye expatlerin kendini guvende hissettigi ulkeler listesinin sonlarinda. https://t.co/8kkn45evjs\n",
      "yazılım mühendisliği için ulusal bir e-posta grubu var mı acaba?\n",
      "diploma denkligimi almaya calisiyorum, butun asamalari tamamlayinca detayli yazarim. epey mesai istiyor :/\n",
      "konsoloslugun yeni binasi guzelmis. personel her zamanki gibi cok yardimci.\n",
      "milano baskonsoloslugundayim. gunun populer konulari askerlik tecil ve kadinlarin evlilik sonrasi soyadi degisikligi\n",
      "su teyze gibi olmak istiyorum o yasa gelebilirsem https://t.co/dm0yjw8g9k\n",
      "hollanda expatler icin en iyi 13. ulke secilmis. turkiye 56, italya 60. sirada. tek ben degilmisim sikayet eden :)\n",
      "https://t.co/jlncsgg7ol\n",
      "#refsq18 e katilmayi dusunmez miydiniz? https://t.co/bz3mdjzob5\n",
      "sunumlarinizi tesekkur veya soru slayti yerine ozet slaytiyla bitirin diyor, iyi fikir! https://t.co/tedm3usw4s\n",
      ".@svlchsn adım adım ile i̇yilik peşinde koşuyor, ben de destek oldum. kampanya sayfasi: https://t.co/vuiriu1tpg #iyilikpesindekos\n",
      "bu yıl instagram hesabım şarkılı türkülü kutlamalarla doldu taştı, ne güzel. hepimizin cumhuriyet bayramı kutlu olsun! 🇹🇷🇹🇷🇹🇷\n",
      ":( https://t.co/sbpaczd3dt\n",
      "tweet ve kullanici adi uyumu :) https://t.co/suks3jxacd\n",
      "#bigearth projesi #uzaktanalgilama #remotesensing alaninda 2 #postdoc ariyor. https://t.co/mpgwixwxm8\n",
      ".@wc_refsq  25 eylul ozet, 2 ekim bildiri gonderimi icin son gun! konferans 19-22 mart arasi utrecht'te! https://t.co/2d2n9ql8jy\n",
      "#utrecht newcomer's guide: https://t.co/l4whxoqjhi\n",
      "3'u kadin 4 turk arastirmacinin projeleri kabul edilmis, 2 proje turkiye'de, 1'i italya'da 1'i ispanya'da yurutulec… https://t.co/2jxqxfpnoi\n",
      "cevreniz genisledikce ictenlikle sohbet edebileceginiz insan sayisi arttigindan sosyal etkinlikler daha cekilir oluyor.\n",
      "konferanslarda havadan sudan konusma rehberi https://t.co/gotbwploip\n",
      "ilk defa ben dinleyiciler arasidayken konusmaci daha once yaptigim bir ise atifta bulundu. hayat bana guzel!\n",
      "bazen kendimi boyle yakaliyorum, farkindalik onemli... https://t.co/hgj3x1yjkd\n",
      "#heavymetal sevenler icin: bir arkadasin 5026 albumu degerlendirdigi site https://t.co/xh7brq669n\n",
      "#kitapagacihollanda olarak bu pazar @mariolevi_ den i̇çimdeki i̇stanbul fotoğrafları'ni tartisacagiz.   katilmak isteyenleri bekleriz.\n",
      "turkiye'deki haber sitelerine de bu ozellik gelsin lutfen. https://t.co/kkbrjussdf\n",
      "got'un yeni sezonunda gordugumuz zincirlenmis kitaplara dair bir yazi  ve video https://t.co/r6xtgegpyd\n",
      "2 yil once milano'da gormustum bu yesil apartmani. fotograf bu sabah tekrar karsima cikti. https://t.co/q2iggghyau\n",
      "yardimci docent begum demir (uni. of trento) big earth adli projesiyle erc starting grant  almaya hak kazandi. \n",
      "#turkbilimdiasporasi\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "df_all= df_all.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "\n",
    "for m in df_all['Tweets']:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "disa_donuk=['!',\"konser\",\"arkadaş\",\"oley\",'hadi',\"hey\",'tatlım','canım','kuzum','bebek','bebeğim','mükemmel','şaka',\n",
    "            'selam','kutlarım','sosyal']\n",
    "ice_donuk=['yalnız','keşke','pişman','ağla','gözyaşı','utanç','hayır','peki','belki','bilgilendirici','ciddi']\n",
    "\n",
    "gercekci=['mümkün','net','olamaz','olur','oldu','olacak','tamam']\n",
    "sezgisel=['belki','muhtemelen','acaba','ihtimal','his','düş','rüya','sevgi','sevmek','sezgi','seviyorum','hayranım',\n",
    "         'gerçeklik']\n",
    "\n",
    "dusunen=['düşünce','düşünüyorum','aslında','mantıklı','doğru','yanlış','tespit','olmalı','tahmin','anlamlı','manalı','şüpheli',\n",
    "         'şüpheci','çünkü']\n",
    "hassas=['kırık','buruk','hüzün','kırgın','ağla','yeterince','teşekkür','hassas','kırılgan']\n",
    "\n",
    "sorgulayan=['neden','ne','nerede','niçin''ara','zaman','saat','ilk','son','net']\n",
    "algılari_acik=['öğrendim','öğretici','bence',]\n",
    "\n",
    "#Dışa dönük / Gerçekçi / Düşünen / Sorgulayan\n",
    "Kisilik_1=[]\n",
    "\n",
    "#İçe dönük / Gerçekçi / Düşünen / Sorgulayan\n",
    "Kisilik_2=[]\n",
    "\n",
    "#Dışa dönük / Gerçekçi / Hassas / Sorgulayan\n",
    "Kisilik_3=[]\n",
    "\n",
    "#İçe dönük / Gerçekçi / Hassas / Sorgulayan\n",
    "Kisilik_4=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_disa_donuk = df_all['Tweets'].str.contains('|'.join(disa_donuk))\n",
    "total_ice_donuk = df_all['Tweets'].str.contains('|'.join(ice_donuk))\n",
    "\n",
    "total_gercekci = df_all['Tweets'].str.contains('|'.join(gercekci))\n",
    "total_sezgisel = df_all['Tweets'].str.contains('|'.join(sezgisel))\n",
    "\n",
    "total_dusunen = df_all['Tweets'].str.contains('|'.join(dusunen))\n",
    "total_hassas = df_all['Tweets'].str.contains('|'.join(hassas))\n",
    "                                           \n",
    "total_sorgulayan = df_all['Tweets'].str.contains('|'.join(sorgulayan))\n",
    "total_algılari_acik = df_all['Tweets'].str.contains('|'.join(algılari_acik)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  disa_donuk ice_donuk gercekci sezgisel dusunen hassas sorgulayan  \\\n",
      "0      False     False    False    False   False  False      False   \n",
      "1      False     False    False    False   False  False      False   \n",
      "2      False     False    False    False   False  False       True   \n",
      "3       True     False    False    False   False  False      False   \n",
      "4      False     False    False    False   False  False      False   \n",
      "5      False     False    False    False   False  False      False   \n",
      "6      False     False    False    False   False  False      False   \n",
      "7      False     False    False    False   False  False      False   \n",
      "8      False     False    False    False   False  False      False   \n",
      "9      False     False    False    False   False  False      False   \n",
      "\n",
      "  algılari_acik  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "5         False  \n",
      "6         False  \n",
      "7         False  \n",
      "8         False  \n",
      "9         False  \n"
     ]
    }
   ],
   "source": [
    "df_total=pd.concat([total_disa_donuk,total_ice_donuk,total_gercekci,total_sezgisel,total_dusunen,total_hassas,total_sorgulayan,total_algılari_acik],ignore_index=True, axis=1)\n",
    "df_total.columns = [ 'disa_donuk','ice_donuk','gercekci','sezgisel','dusunen','hassas','sorgulayan','algılari_acik']                                         \n",
    "\n",
    "print(df_total.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dışa Dönük ! \n"
     ]
    }
   ],
   "source": [
    "Dıs=df_total['disa_donuk'][df_total['disa_donuk']==True].count().sum()\n",
    "Ic=df_total['ice_donuk'][df_total['ice_donuk']==True].count().sum()\n",
    "\n",
    "if(Dıs>Ic):\n",
    "    print(\"Dışa Dönük ! \")\n",
    "elif(Dıs==Ic):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"İçe Dönük...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerçekçi ! \n"
     ]
    }
   ],
   "source": [
    "G=df_total['gercekci'][df_total['gercekci']==True].count().sum()\n",
    "S=df_total['sezgisel'][df_total['sezgisel']==True].count().sum()\n",
    "\n",
    "if(G>S):\n",
    "    print(\"Gerçekçi ! \")\n",
    "elif(G==S):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"Sezgisel...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dengeli.\n"
     ]
    }
   ],
   "source": [
    "D=df_total['dusunen'][df_total['dusunen']==True].count().sum()\n",
    "H=df_total['hassas'][df_total['hassas']==True].count().sum()\n",
    "\n",
    "if(D>H):\n",
    "    print(\"Düşünen..\")\n",
    "elif(D==H):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"Hassas...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorgulayan..\n"
     ]
    }
   ],
   "source": [
    "Sor=df_total['sorgulayan'][df_total['sorgulayan']==True].count().sum()\n",
    "Alg=df_total['algılari_acik'][df_total['algılari_acik']==True].count().sum()\n",
    "\n",
    "if(Sor>Alg):\n",
    "    print(\"Sorgulayan..\")\n",
    "elif(Sor==Alg):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"Algıları Açık...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
